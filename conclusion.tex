\section{Conclusion and Future Work} \label{sec:conclusion}
% Primary: Aur√©lien

As we acquire larger, likely more error-prone, platforms, effectively protectign
applications from platform faults becomes critical. Current production
fault-protection techniques rely on checkpoint/restart to ensure such progress.
However, these techniques, by their very nature, regularly save the application state
to stable storage, and therefore increase the burden of the already overtaxed I/O
subsystem.

Considering a comprehensive I/O interference model for platforms susceptible to I/O
contention, we designed multiple I/O scheduling algorithms that target improving
overall platform job throughput via waste minimization. We also theorized a
lower-bound for platform waste for I/O constrained checkpointing workloads. We use
this this theoretical lower-bound to demonstrate the effectiveness of our \emph{least
  waste} I/O scheduling algorithm and to compare its performance with other I/O
scheduling strategies.  Our scheduling strategy invariably outperforms the others
with respect to the platform efficiency; Unsurprisingly, the biggest gains are
rendered on the platforms with a lowest MTBF or greater degrees of under-provisioned
I/O; Through simulation, we also show a path to supporting application-level
checkpointing while maintaining a 80\% platform efficiency, all without a large
investment in the I/O partition.

% In this paper we presented a comprehensive model to capture interference
% between multiple applications performing fault-tolerance related I/O
% on a shared HPC system. We designed multiple algorithms
% to schedule and order the checkpointing I/O workload, with the intent of
% diminishing the average slowdown sustained by applications on the
% platform induced by sharing the I/O subsystem, \ie improve the throughput
% of the platform. We formulated a steady-state analysis of a scenario
% where CR-CR interference is avoided, which helps us
% define a theoretical baseline for achievable performance in I/O
% constrained checkpointing workloads.
% We designed a event-based simulator that permits
% executing typical HPC workloads on current and prospective systems.
% With this simulator we have been able to demonstrate that our proposed
% heuristic improves the platform efficiency. Unsurprisingly the gain is
% more marked on platforms with a challenging MTBF or with
% under-provisioned I/O, but our heuristic improves the efficiency in
% all cases.  We also simulated the situation on a not yet available
% platform, this time with the goal of providing guidance in the
% general I/O requirements for future HPC systems to be able to
% sustain checkpointing with the desired 80\% efficiency, a goal that
% we have found achievable with a third of the I/O aggregate bandwidth
% requirements when the system employs a smart checkpointing policy.

As burst-buffers and other NVRAM storage mechanisms become more common, a natural
extension of this work would consider the impact on I/O contention/interference for
platforms that leverage burst-buffer technologies. Increasing the available I/O
bandwidth leads to reduced waste (due to the decrease in checkpoint duration but also
an increase in the optimal checkpoint frequency and therefore a decrease in the
restart time), while providing relief to the shared I/O subsystem to better absorb
additional checkpoint information. We speculate that scheduling parallel filesystem
I/O with a heuristic that prioritizes jobs to minimize failure impact can help to
improve overall burst-buffer efficiencies. Such a heuristic would build upon the
strategies discussed in this work and extend them to the new framework.

% As burst-buffers and other NVRAM storage are becoming more common
% in PFS architecting, a natural extension of this work is to consider the effect
% of I/O contention/interference with hierarchies, in which subgroups of
% nodes (\eg a cabinet) may share a burst buffer, and thus experience
% interference for I/O in that same group, but be immune to interferences
% from I/O from other groups. Another interesting point with burst-buffers,
% is that space availability, in addition to bandwidth, may become
% contentious. The speed at which the burst-buffers can be committed to
% the sink PFS (possibly creating interference between multiple burst-buffers being
% flushed to the sink PFS simultaneously) now interplays with the
% optimal checkpoint frequency of applications, and can cause some
% applications running out of burst-buffer space. Again, we postulate that
% scheduling the commits to the PFS sink with an heuristic that prioritizes
% applications whose loss in failure cases would be more costly
% can play a role in improving the efficiency of the whole burst-buffers
% system.
