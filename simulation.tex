% !TEX root =  ipdps18.tex

\section{Simulation Framework}
\label{sec:simulator}
% Primary: Thomas

In order to evaluate the performance of the proposed approaches, we
ran a large set of discrete event simulations that we describe in this
section. Simulations\footnote{The simulator described here is publicly
  available
  on~\url{https://github.com/SMURFSorg/InterferingCheckpoints}.} are
instantiated by a set of initial conditions that define a set of
application classes, the distribution of resource usage between
application classes, and by the main characteristics of the platform
on which these will execute.

\paragraph*{High level parameters}
Application classes are characterized by the following parameters:
size of initial input and output, size of checkpoints, quantity of
work to execute, number of nodes to use, quantity of diffuse I/O to
execute during the entire life of the job, and execution time.
Platforms are characterized by the number of nodes, a system Mean Time
Between Failures, and an aggregated I/O subsystem bandwidth that is
shared between the different nodes. We assume that the bandwidth when
reading from and writing to the filesystem is symmetric, hence
$\ckpt{i}=\reco{i}$ for each application class $\app{i}$.

A simulation first selects randomly a list of jobs that are instances
of the different application classes. This list is ordered by job
priority, and constrained by two parameters: the minimum simulated
time to consider, and the relative proportion of platform resources
allocated to each application class.

As an example, we consider the subset of application classes given by
the APEX workflows report for the subset of application classes of
LANL (EAP, LAP, Silverton and VPIC), simulated as running over the
Cielo supercomputer, for a minimal execution time of 60h. A simulation
will randomly instantiate one of the four classes, assigning a work
duration uniformly distributed between $0.8w$ and $1.2w$, where $w$ is
the typical walltime specified for the chosen application class, and
count the resource allocated for this application class, until A) the
simulated execution would necessarily run for at least 2 months, and B) the
amount of resource used by the selected class is within 1\% of the
target goal of the representative workload percentage defined in the
APEX workflows report (see Table~\ref{table:lanl}).

Once this list of jobs is defined, a set of node failures dates is
computed. Dates of failures are placed following an exponential
distribution with the MTBF required for the simulation. At the chosen
dates, which node is hit by the failure is chosen uniformly between
all nodes of the simulated platform. The list of jobs and the date and
location of failures constitute the initial conditions of a
simulation.

\paragraph*{Job Scheduling}
First, an initial job schedule is computed: jobs are set to start and
end at planned dates and on planned nodes, depending on their
characteristics, their priority, and resource availability. The job
schedule follows a simple first-fit strategy. We simulate an online
scheduling, and every time a job ends before its planned date
(because of a failure, or because it reached the end of its execution
before the planned date), the schedule is amended by re-scheduling all
jobs that were not started yet.

\paragraph*{Execution Simulation}
Once a job is started, it first executes its initial input. It then 1)
executes some work for a certain period before it 2) checkpoints. These two
steps are repeated until all planned work is executed, after which the
final output is executed by the job, before it ends. At any time
during the execution, a node hosting the job may be subject to a
failure (striking at pre-computed dates and places). When that
happens, the job is terminated, and a new job is added to the list of
jobs to schedule. That new job represents the restart of the failed
one: it has similar characteristics, but its initial input
corresponds to the restart size, and its work time corresponds to
the remaining work from the last successful checkpoint. To reflect a
frequent job scheduling policy on shared platforms, the restarting job
priority is set to the maximal, so that it gets a higher chance to
obtain an allocation fast and complete the execution.

As mentioned in Section~\ref{sec:variants}, checkpointing periods can
either be dynamic or fixed. For fixed periods, an ordinary heuristic
is to take a checkpoint every hour, with the reasoning that in the
worst case, only one hour of work can be lost. In the reminder of
this paper we will refer to these two frequency variants as Fixed,
when the checkpoint period is fixed to 1 hour, and as Daly when the
optimal checkpoint frequency is defined using the Daly period. For the
\leastwaste algorithm, the checkpoint interval is at least the Daly period
(by construction), and a Fixed version is pointless.

\ifTR

\paragraph*{Interference Models} Simulations implement each of the
interference model and avoidance strategies defined in
Section~\ref{sec:algorithms}: for \propfixed and \propdaly,
interfering I/O and checkpoints get a portion of the available
aggregated bandwidth proportional to the number of nodes they use, and
inversely proportional to the number of nodes involved for all
jobs doing I/O; for \bfifofixed and \bfifodaly, I/O requests
and checkpoints are ordered in a first-come first-serve strategy, and
when they are selected, obtain the full bandwidth; for \fifofixed and
\fifodaly, I/O requests and checkpoints are served in order, but the
simulation adds all the time waiting for a checkpoint to start as
progress in the computation for the job; and for \cooperative,
the same is implemented, but I/O are ordered to minimize the waste in
Equations~\eqref{eq.selection} and~\eqref{eq.selection2}.

Note that in the scheduled I/O methods (\fifononblock and \cooperative),
initial inputs and final outputs are blocking (the job
cannot progress during the I/O until it is served), but checkpoints
are non blocking, which entails that if a failure hits the job,
it may have to re-execute from a checkpoint far in its past, if it was not
granted access to the filesystem for a long time.
\else
Simulations implement each of the interference models and avoidance
strategies defined in Section~\ref{sec:algorithms}.
\fi

\paragraph*{Method of statistics collection from simulations}
As we compare all the scheduling strategies, each simulation is run
once per strategy with the same initial conditions (list of jobs with
initial priorities and date and location of failures). Performance
statistics are collected over each simulation. In order to consolidate
these measures over many simulations, statistics are taken over a
segment of fixed length of each simulation.  To capture steady-state,
this segment excludes both the first day of the simulation (in which
jobs might be synchronized artificially because a subset
starts at the same date), and the last day of the simulation (in which
a large amount of resource may not be used as new jobs are not
added to the workload). We simulate a large number of such runs (at
least a thousand simulations per shown measurement), and compute the
first, and ninth decile and the first and third quartile of the
performance for each statistic, as well as the mean value.
