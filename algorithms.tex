% !TEX root =  ipdps18.tex

\section{Scheduling Policies}\label{sec:algorithms}
% Aurelien & George
\dca{I think this section currently conflates general concepts with specific
  algorithmic details. Whenever we believe the content is close to fixed, I'd like to
  take a pass at refactoring the discussion.}

In this section, we present the algorithms used to schedule applications
and I/O workload in order to alleviate the effect of concurrent access
to I/O resources. The first algorithm (\nocoop) represents the status-quo  in
which applications are scheduled in a non-cooperative manner, which may
incur interference on I/O resource access and wait time. The second
algorithm (\fifoblock) inserts some coordination between I/O activities purely at
the filesystem level. Application that want to checkpoint are considered in
a FIFO ordering. When an application finishes a checkpoint, the head of
the line application is granted the checkpointing token and proceed,
other applications in the queue remain blocked in the checkpointing
routine. The third algorithm (\fifononblock) is similar, except it assumes
that burst buffers are available to absorb the temporary influx of
checkpoint data. In this case, the application blocks for the time it
takes to stage the checkpoint on the burst buffer, however, the application
receives full protection from fault only when the checkpoint is fully
migrated to the PFS. Last, we propose an heuristic (\leastwaste) whose goal is to
select the application that inflicts the least overhead on the system.
Each application checkpoints in a non-blocking manner, and instead of
following a FIFO order to select the next checkpointing application,
we compute the prospective waste incurred by selecting one of the
checkpointing applications, and select the best one at that moment. Note
that given the time dependent nature of that descision, the selection may
not be the global optimum, but only an approximation given currently
available information about the system status.

\subsection{Scheduling applications}
%TODO: remove/rewrite this section it is too attached to the instanciations. =

\begin{itemize}
\item We take a large number of applications. These applications belong to a few
  classes (say 4 classes). We enforce the percentage per class that is reported in
  the APEX paper.  Each application comes with: class, number of processors, input
  I/O size, output I/O size, checkpoint size, CPU time (equal to wall-time reported
  in APEX paper). To avoid side effects induced by having hundreds of completely
  identical applications, we use normal distributions for CPU time with mean equal to
  original APEX value and small standard deviation (say 10\%). \dca{Put in model
    section?}
  \item We shuffle the applications and present them all in a big queue to the scheduler,
  which uses a simple first-fit algorithm. No user reservation, plain greedy. But we do assume the scheduler has access to the entire list of pending applications.
\item We also make the assumption that the applications know precisely
  the necessary wall-time. This diverges from a real scenario but
  allow us to only take in account one type of disturbance: an
  application is slower than expected due to C/R overheads (and will
  extend its original wall-time). \dca{Put in model section?}
  \item When an application fails, we resubmit it with a new wall-time equal to the fraction that remains from the last checkpoint.  Input I/O becomes recovery. Output I/O is not modified.

We put back the restarted application at the head of the scheduling queue
  (so that it has a chance to finish it's previously allotted wall time
  immediately, given that the resources it previously occupied are
  presumably available), and force a reschedule with every application that
  has not started yet (already running applications are left to continue
  their work).
\end{itemize}

\subsection{Dealing with interference for non-cooperative application scheduling}
\begin{itemize}
%  \item For coherence, we use the same policy for input I/O, output I/O and checkpoint operations \todo[inline]{we may want to separate Input+recovery from output+checkpoint (bidirectional channels)}
%  \todo[inline]{answer: we could but not sure it is 100\% independent; and it would complicate things without changing the story.}
  \item Blocking: only one application can perform I/O operations at the given time-step.
  I/O requests are served on a FCFS basis. When an application has requested an I/O
  operation, it waits idle until being served. \dca{Technically, blocking is
    cooperative!}
  \item Sharing: the I/O resource is shared at every time-step to serve all concurrent requests. Sharing is fair, i.e., bandwidth is inversely proportional to number of requests.
  \item Here is an example:
  application $A_{1}$ wants to perform five gigabytes of I/O at time $t$,
  and available bandwidth is
  $1$ gigabyte per second. If there is no other request, the operation will take five seconds.
  Now application $A_{2}$ (with same number of processors as $A_{1}$, hence with same assigned bandwidth in the sharing policy) wants to perform two gigabytes of I/O at time $t+1$.
  \begin{itemize}
  \item Blocking: $A_{2}$'s operation is delayed until time $t+5$ and will complete at $t+7$.
  \item Sharing: Instead of taking $2$ seconds, $A_{2}$'s operation will take $4$ seconds, because the bandwidth is shared with $A_{1}$ during its whole transfer. As a results, $A_{2}$'s operation completes at $t+5$ while $A_{1}$'s  operation is slowed down during four units and now completes at $t+7$.
  \end{itemize}
\end{itemize}

\subsection{Orchestrating I/O for cooperative application scheduling}

\subsubsection{Strategy}

\begin{itemize}
  \item We always use the blocking strategy but not the FCFS policy.
  \item Instead, whenever an I/O operation completes at time $t$, we have a pool of application candidates:
  \begin{itemize}
   \item Category \IOcat $\Catiocat$: Applications $A_{i}$, $1\leq i \leq r$, which need to do input I/O, output I/O or recovery
  \item Category \Ckptcat $\Catckptcat$: Applications $A_{i}$, $r+1\leq i \leq r+s$,
  whose last checkpoint took place no later than time $t - \period{Daly}(A_{i})$, where $\period{Daly}(A_{i})$ is the Young/Daly period for $A_{i}$.
  \end{itemize}
  \item To decide which application is given priority among all $r+s$ candidates applications in $\Catiocat \cup \Catckptcat$, we select the one that minimizes the expected total waste induced by this choice, as explained below.
  \end{itemize}

 \subsubsection{Selection among candidate applications}

At the current time-step, there are $r+s$ candidates in $\Catiocat \cup \Catckptcat$:
\begin{itemize}
  \item Application $A_{i} \in \Catiocat$, $1\leq i \leq r$,
  has an I/O request of volume $v_{i}$ and enrolls $q_{i}$ processors. At the current time-step, $A_{i}$ initiated its I/O request $d_{i}$ seconds ago, and has been idle since $d_{i}$ seconds.
 \item Application $A_{i} \in  \Catckptcat$ has a checkpoint of duration $C_{i}$ seconds,
  and enrolls $q_{i}$ processors. At the current time-step, $A_{i}$ took its last checkpoint
  $d_{i}$ seconds ago, and keeps executing until it can checkpoint. For the record, we must have $d_{i} \geq \period{Daly}(A_{i})$
  since $A_{i}$ is a candidate.
  \end{itemize}

If we select application $A_{i}$ to perform I/O,  the expected waste $\wap{i}$ incurred
to the other $r+s-1$ candidate applications in  $\Catiocat \cup \Catckptcat$ is computed as follows.
Assume first that $A_{i} \in \Catiocat$. Then  $A_{i}$ will use the I/O resource for $v_{i}$ seconds.
\begin{itemize}
  \item Every other application $A_{j} \in \Catiocat$ will stay idle for $v_{i}$ additional seconds,
  hence its waste $\wapp{i}{j}$ is
  $$\wapp{i}{j} = q_{j} (d_{j} + v_{i})$$
  since there are $q_{j}$ processors enrolled in $A_{j}$ and idle for $d_{j} + v_{i}$ seconds. Note that for $A_{j} \in \Catiocat$, the waste $\wapp{i}{j}$ is deterministic.
  \item Every application $A_{j} \in \Catckptcat$ will continue executing for $v_{i}$ additional seconds, hence will be exposed to the risk of a failure that will strike within $v_{i}/2$ seconds on average. The probability of such a failure is $v_{i}/\mu_{j}$, where $\mu_{j}$ is the
  MTBF of application $A_{j}$. Since $A_{j}$ enrolls $q_{j}$ processors, we have $\mu_{j} = \muind/q_{j}$, where $\muind$ is the individual MTBF per processor. With this probability,
  the $q_{j}$ processors will have to recover and re-execute $d_{j} + v_{i}/2$ seconds of work,
  hence the waste $\wapp{i}{j}$ is
     $$\wapp{i}{j} = \frac{v_{i}}{\mu_{j} } q_{j} (R_{j} + d_{j} + \frac{v_{i}}{2}) =
     \frac{v_{i}}{\muind} q^{2}_{j} (R_{j} + d_{j} + \frac{v_{i}}{2})$$
     where $R_{j}$ is the recovery time for $A_{j}$.
Note that for $A_{j} \in \Catckptcat$, the waste $\wapp{i}{j}$ is probabilistic.
 \end{itemize}
 Altogether, the expected waste $\wap{i}$ incurred
to the other $r+s-1$ candidate applications is
$$\wap{i} = \sum_{A_{j} \in \Catiocat, j\neq i} \wapp{i}{j} + \sum_{A_{j} \in \Catckptcat} \wapp{i}{j}$$
We obtain
\begin{equation}
\label{eq.selection}
\begin{array}{ll}
 \wap{i} = & v_{i} \times \left( \sum_{1 \leq j \leq r, j\neq i} q_{j} (d_{j} + v_{i}) \right.\\
 & + \left. \sum_{r+1 \leq j \leq r+s}   \frac{q^{2}_{j}}{\muind} (R_{j} + d_{j} + \frac{v_{i}}{2}) \right)
 \end{array}
\end{equation}

 Assume now that the selected application $A_{i} \in \Catckptcat$. Then  $A_{i}$ will use the I/O resource for $C_{i}$ seconds instead of $v_{i}$ seconds for $A_{i} \in \Catiocat$. We directly obtain the counterpart of Equation~\eqref{eq.selection} for its waste $\wap{i}$:
 \begin{equation}
\begin{array}{ll}
 \wap{i} = &  C_{i} \times \left( \sum_{1 \leq j \leq r} q_{j} (d_{j} + C_{i}) \right.\\
 & + \left.  + \sum_{r+1 \leq j \leq r+s, j\neq i}   \frac{q^{2}_{j}}{\muind} (R_{j} + d_{j} + \frac{C_{i}}{2}) \right)
  \end{array}
\end{equation}

 Finally, we select the application $A_{i} \in \Catiocat \cup \Catckptcat$ whose waste
 $\wap{i}$ is minimal.


%\subsubsection{Selection in category \IOcat}
%\label{sec.iocat}
%
%  Let $(A_{i})_{1 \leq i \leq m}$ be the application candidates of category \IOcat.
%  Application $A_{i}$ has an I/O request of volume $v_{i}$ and enrolls $q_{i}$ processors.
%  Choosing $A_{i}$ makes every other candidate application $A_{j}$, $j \neq i$, keep $q_{j}$ processors idle during a time
%  proportional to $v_{i}$, so we choose $i$ that minimizes
%  $$(\sum_{j \neq i} q_{j}) \times v_{i}$$
%
%\subsubsection{Selection in category \Ckptcat}
%\label{sec.ckptcat}
%
%Let $(A_{i})_{1 \leq i \leq m}$ be the application candidates of category \Ckptcat.
%  Application $A_{i}$ has a checkpoint of duration $C_{i}$ seconds,
%  and enrolls $q_{i}$ processors. At the current time-step, $A_{i}$ took its last checkpoint
%  $d_{i}$ seconds ago (and for the record, we must have $d_{i} \geq \period{Daly}(A_{i})$
%  since $A_{i}$ is a candidate).
%   Choosing $A_{i}$ puts every other candidate application $A_{j}$, $j \neq i$,
%   at the risk of a failure that will strike within $C_{i}/2$ seconds on average.
%   Let $\bar{Q}_{i} = \sum_{j \neq i}q_{j}$ be the total number of
%   processors belonging to applications that want to checkpoint.
%   With probability $C_{i}/(\muind/\bar{Q}_{i})$ there will be a fault on one of these
%   processors. Here $\muind$ is the individual MTBF, hence we divide it by $\bar{Q}_{i}$
%   to get the MTBF over all processors at risk.
%
%   With probability $q_{j}/\bar{Q}_{i}$ the fault will strike application $A_{j}$ and incur a waste of duration $d_{j} + C_{i}/2$ for each of its $q_{j}$ processors. Altogether, the
%   expected amount of wasted time is
%   $$\frac{C_{i}}{(\muind/\bar{Q}_{i}) } \times \sum_{j \neq i}\frac{q_{j}}{\bar{Q}_{i}}(d_{j}+ \frac{C_{i}}{2})q_{j} = \frac{C_{i}}{\muind} \sum_{j \neq i} q_{j}^{2}(d_{j}+ \frac{C_{i}}{2})$$
%    and we choose $i$ that minimizes the above quantity.
