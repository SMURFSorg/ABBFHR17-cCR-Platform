% !TEX root =  ipdps18.tex

\section{I/O Scheduling Algorithms}
\label{sec:algorithms}
% Aurelien & George

In this section, we present the applications I/O scheduling algorithms used to study
the effects of concurrent I/O activities.  The first algorithm (\nocoop) represents
the status-quo in which I/O activities are scheduled independently and may incur
slowdowns due to I/O resource contentions. The second algorithm (\fifoblock)
coordinates I/O activity to eliminate interference: I/O operations are scheduled in a
First-Come-First-Serve (FCFS) fashion, and only one I/O operation executes at any
given time while other I/O requests are blocked until their turn comes.  The third
algorithm (\fifononblock) is similar, except that jobs that are waiting
for the I/O token to checkpoint continue working until their turn comes.
Last, we propose our heuristic (\leastwaste) that improves on \fifononblock by giving
the I/O token to the I/O operation that will minimize system waste. Note that unlike the blocking approaches (\nocoop
and \fifoblock), non-blocking optimizations (\fifononblock and
\cooperative) require application code refactoring.

 % \dca{what about the
 %  case when an application must communicate before its computation can proceed?
 %  E.g. it continued execution but then arrived at a point at which it needs external
 %  input or coordination? Which brings up another question: does our model implicitly
 %  (or explicitly) handle synchronization/barrier type communication
 %  with no data?}
 % TH -> DCA: We consider a workflow batch scheduling typical of HPC
 % platforms. Applications do not communicate or synchronize with each
 % other, except through the filesystem, through their initial input
 % and final ouput. Initial input and final output are always blocking.

%Instead of following a FCFS order to select the next I/O application,
%for each requesting job, the heuristic computes the prospective
%waste incurred by delaying its I/O (considering checkpoint and
%probabilistic recovery costs, idle time, etc.) when selecting another
%job, and selects the one that minimizes the waste increase
%at the current instant.

\subsection{\nocoop I/O Scheduling}

In \nocoop I/O scheduling, jobs are executed to fill-up the system based on processor
availability, and their I/O workload (including CR activities) are not coordinated by
any system of cooperation.  Instead, jobs use the parallel file system
assuming they are the sole user -- with no modification to their access pattern to
accommodate for possible interferences. Researchers have observed that such
concurrent I/O resource access can decrease the I/O bandwidth observed by the running
jobs~\cite{Dorier2015}.  Under the conditions of an under-provisioned filesystem, our
model renders to each contending I/O operation a decrease in bandwidth linearly
proportional to the number of contending operations.  We account for the additional
delays imposed by this decreased bandwidth as waste. Since subsequent checkpoints are
scheduled to start after $\period{i}-\ckpt{i}$, and delays may result in checkpoint
commit times longer than $\ckpt{i}$, the resultant checkpoint period may be longer
than $\period{i}$. This is consistent with an oblivious I/O policy that does not
consider for issues stemming from potential I/O contention.

% GB: The variants are described in the Simulation
% In the \nocoop algorithm, we consider two variants where checkpoints are
% tentatively taken at 1) fixed frequency (\propfixed), or 2) at the Daly frequency
% (\propdaly).

\subsection{Blocking \fifoblock FCFS I/O Scheduling}
\label{sec:fcfsblock}

A simple optimization to the \nocoop scheme is to favor one of the jobs' I/O request
over all the others. While the overall throughput may remain unchanged (given an
efficient filesystem implementation), the favored job completes its I/O
workload faster (\ie, in time $\ckpt{i}$ for a job of class $\app{i}$).  In
the \fifoblock scheme, I/O requests are performed sequentially, in request arrival
order. Jobs with outstanding I/O requests are blocked until their requests are
completed.

Assuming a favorable linear interference model, a simple workload with two jobs can
show the potential advantage of the \fifoblock over \nocoop strategy.  If the two
jobs simultaneously request I/O transfers of similar data volume, $V$, in the \nocoop
strategy, both jobs take $\frac{V}{\frac{\bandavail}{2}}$ time to complete their I/O.
In the \fifoblock strategy, the first scheduled job takes only
$\frac{V}{\bandavail}$, while the second job waits $\frac{V}{\bandavail}$
before its own I/O starts, but then executes at full available bandwidth completing
in $\frac{2V}{\bandavail}$.  Reducing I/O interference reduces the average I/O
completion time (although fairness may be decreased).  Once again, however, observed
checkpoint durations may increase past $\ckpt{i}$, due to I/O scheduling wait time,
and the checkpointing period may be, on average, larger than the desired
$\period{i}$.

% GB: The variants are described in the Simulation
% In the \fifoblock algorithm, we again consider two variants, where checkpoints are
% tentatively taken at 1) fixed frequency (\bfifofixed), or 2) at the Daly frequency
% (\bfifodaly).

\subsection{Non-Blocking \fifononblock FCFS I/O Scheduling}
\label{sec:fcfsnonblock}

The previous strategy trades the cost of I/O interferences for
idle time, as jobs perform a blocking (idle) wait for the I/O token.
If the application developer can refactor the program code to continue
computing while awaiting I/O request completions, it becomes possible
to replace otherwise idle wait time with useful computation. In the
\fifononblock algorithm, when the previous checkpoint ends at time
$t_{now}$, a tentative time for the next checkpoint is set at
$t_{req}=t_{now}+\period{i}-\ckpt{i}$.  At time $t_{req}$, a
non-blocking I/O request is made to request the I/O token -- the I/O
token is still scheduled FCFS according to request arrival time.  The
job continues its computation until the scheduler informs it that the
I/O token is available. At this point, the job must generate its
checkpoint data as soon as possible (or after a short
synchronization\footnote{In user-level checkpointing, the job typically
  finishes its current computing block before generating its
  checkpoint data.}).  In most applications, the granularity of the
work is small enough for a simple approach to be efficient:
applications can use existing APIs in SCR~\cite{Moody10_SCR} or
FTI~\cite{Bautista-Gomez11_FTI} to regularly poll if a checkpoint
should be taken at this time. In this work, we assume that this
resynchronization cost is negligible relative to the checkpoint commit
duration.
%
%\dca{I commented out the example libraries because the described app-to-library
%  probes are different from the necessary library-to-app``callbacks'' or ``upcalls''
% needed in this case}
% See how the text was modified above.
%
Postponing checkpoint I/O increases a job's exposure to failures.  However,
if the job successfully commits the postponed checkpoint, upon a subsequent failure,
the job would restart from the time at which the postponed checkpoint was taken, not
at $t_{req}$ -- a fact that may mitigate the increased risk exposure when
compared to \fifoblock and \nocoop algorithms.

% Then, the job initiates its I/O (checkpointing, initial input, final
% output or recovery). When the active job completes its I/O, the next
% requesting job (in FCFS order) become the active I/O job.

%Aurelien: talked with Thomas and this is not what we want to study here.
% However, that
% state can be initially captured by copy-on-write mechanisms, or stored
% in local memory or in compute node-local burst buffers (\eg local SSD
% drives). Although node-local burst buffers do not offer protection
% against faults, they permit offsetting the transfer of the checkpoint
% data to a later date when the I/O token is available to the job.
% When the job finaly gets the token, the previously scratch-space
% stored checkpoint is transfered to the PFS without interference.
%NOTTODO: something about replacing with last ckpt if token doesn't come in fast enough;
% there's something that doesn't work with the T-C after C depiction: we would rollback unbounded amounts now.
% that's because we do not consider whats commented down here with local scratchpads
% the checkpoint is taken at a date t_c posterior to t_req, and we will restart at t_c, not t_req.

\subsection{\leastwaste Algorithm}
\label{sec:least-waste}

Finally, our \leastwaste algorithm further refines the \fifononblock algorithm by
issuing the I/O token to the job whose I/O request minimizes the total expected waste
(explained hereafter), rather than simply based on request arrival order.  Given the
time-dependent nature of this decision, the selection may not be a global optimum,
but only an approximation given currently available information about the system
status.  For each I/O scheduling decision, at time $t$ (when a previous I/O operation
completes), we consider a pool of $r+s$ candidates from two different categories:

\begin{compactitem}
\item Category \IOcat $\Catiocat$: Jobs $J_{i}$, $1\leq i \leq r$ with an
  (input, output or recovery) I/O request of length $v_{i}$ seconds and enrolls $q_{i}$
  processors. $J_{i}$ initiated its I/O request $d_{i}$ seconds ago and has been idle
  for $d_{i}$ seconds.

\item Category \Ckptcat $\Catckptcat$: Jobs $J_{i}$, $r+1\leq i \leq r+s$,
  with a checkpoint duration of $C_{i}$ seconds and enrolls $q_{i}$ processors.
  $J_{i}$ took its last checkpoint $d_{i}$ seconds ago and keeps executing until the
  I/O token is available for a new checkpoint. Since $J_{i}$ is a candidate,
  $d_{i} \geq \period{Daly}(J_{i})$
\end{compactitem}


If we select job $J_{i}$ to perform I/O, the expected waste $\wap{i}$
incurred to the other $r+s-1$ candidate jobs in  $\Catiocat \cup
\Catckptcat$ is computed as follows. Assume first that $J_{i} \in \Catiocat$.
Then  $J_{i}$ will use the I/O resource for $v_{i}$ seconds.
\begin{compactitem}
%
  \item Every other job $J_{j} \in \Catiocat$ will stay idle for $v_{i}$
  additional seconds, hence its waste $\wapp{i}{j}$ is $$\wapp{i}{j} = q_{j}
  (d_{j} + v_{i})$$ since there are $q_{j}$ processors enrolled in $J_{j}$ that
  remain idle for $d_{j} + v_{i}$ seconds. Note that for $J_{j} \in \Catiocat$, the
  waste $\wapp{i}{j}$ is deterministic.
%
  \item Every job $J_{j} \in \Catckptcat$ will continue executing for
  $v_{i}$ additional seconds, hence will be exposed to the risk of a failure
  that will strike within $v_{i}/2$ seconds on average. The probability of such
  a failure is $v_{i}/\mu_{j}$, where $\mu_{j} =
  \muind/q_{j}$. With this
  probability, the $q_{j}$ processors will have to recover and re-execute $d_{j} +
  v_{i}/2$ seconds of work, hence the waste $\wapp{i}{j}$ is $$\wapp{i}{j} =
  \frac{v_{i}}{\mu_{j} } q_{j} (\reco{j} + d_{j} + \frac{v_{i}}{2}) =
  \frac{v_{i}}{\muind} q^{2}_{j} (\reco{j} + d_{j} + \frac{v_{i}}{2})$$ where
  $\reco{j}$ is the recovery time for $J_{j}$. Note that for $J_{j} \in
  \Catckptcat$, the waste $\wapp{i}{j}$ is probabilistic.
%
 \end{compactitem}
 Altogether, the expected waste $\wap{i}$ incurred
to the other $r+s-1$ candidate jobs is
$$\wap{i} = \sum_{J_{j} \in \Catiocat, j\neq i} \wapp{i}{j} + \sum_{J_{j} \in \Catckptcat} \wapp{i}{j}$$
We obtain
\begin{equation}
\label{eq.selection}
\begin{array}{ll}
 \wap{i} = & v_{i} \times \left( \sum_{1 \leq j \leq r, j\neq i} q_{j} (d_{j} + v_{i}) \right.\\
& + \left. \sum_{r+1 \leq j \leq r+s}   \frac{q^{2}_{j}}{\muind} (\reco{j} + d_{j} + \frac{v_{i}}{2}) \right)
 \end{array}
\end{equation}

Assume now that the selected job $J_{i} \in \Catckptcat$. Then $J_{i}$
will use the I/O resource for $\ckpt{i}$ seconds instead of $v_{i}$
seconds for $J_{i} \in \Catiocat$. We directly obtain the counterpart
of Equation~\eqref{eq.selection} for its waste $\wap{i}$:
 \begin{equation}
\label{eq.selection2}
 \begin{array}{ll}
 \wap{i} = & \ckpt{i} \times \left( \sum_{1 \leq j \leq r} q_{j} (d_{j} + \ckpt{i}) \right.\\
& + \left. \sum_{r+1 \leq j \leq r+s, j\neq i}   \frac{q^{2}_{j}}{\muind} (\reco{j} + d_{j} + \frac{C_{i}}{2}) \right)
 \end{array}
\end{equation}

Finally, we select the job $J_{i} \in \Catiocat \cup \Catckptcat$
whose waste $\wap{i}$ is minimal.  Contrarily to the previous
scenarios, we do not consider the variant where the checkpointing
frequency is arbitrarily set, because the \leastwaste algorithm is
designed to optimize checkpoint frequencies across jobs.
