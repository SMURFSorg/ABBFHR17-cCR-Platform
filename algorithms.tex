\section{I/O Scheduling Algorithms}\label{sec:algorithms}
% Aurelien & George
\dca{I think this section currently conflates general concepts with specific
  algorithmic details. Whenever we believe the content is close to fixed, I'd like to
  take a pass at refactoring the discussion.}

  %TODO: again this is part of the model
  %TODO: looks like I'm not using the right terminology for blocking/non-blocking/sharing...
  \subsection{Dealing with interference for non-cooperative application scheduling}
  \begin{itemize}
    \item For coherence, we use the same policy for input I/O, output I/O and checkpoint operations \todo[inline]{we may want to separate Input+recovery from output+checkpoint (bidirectional channels)}
    \todo[inline]{answer: we could but not sure it is 100\% independent; and it would complicate things without changing the story.}
    \item Blocking: only one application can perform I/O operations at the given time-step.
    I/O requests are served on a FCFS basis. When an application has requested an I/O
    operation, it waits idle until being served. \dca{Technically, blocking is
      cooperative!}
    \item Sharing: the I/O resource is shared at every time-step to serve all concurrent requests. Sharing is fair, i.e., bandwidth is inversely proportional to number of requests.
    \item Here is an example:
    application $A_{1}$ wants to perform five gigabytes of I/O at time $t$,
    and available bandwidth is
    $1$ gigabyte per second. If there is no other request, the operation will take five seconds.
    Now application $A_{2}$ (with same number of processors as $A_{1}$, hence with same assigned bandwidth in the sharing policy) wants to perform two gigabytes of I/O at time $t+1$.
    \begin{itemize}
    \item Blocking: $A_{2}$'s operation is delayed until time $t+5$ and will complete at $t+7$.
    \item Sharing: Instead of taking $2$ seconds, $A_{2}$'s operation will take $4$ seconds, because the bandwidth is shared with $A_{1}$ during its whole transfer. As a results, $A_{2}$'s operation completes at $t+5$ while $A_{1}$'s  operation is slowed down during four units and now completes at $t+7$.
    \end{itemize}
  \end{itemize}




In this section, we present the algorithms used to schedule applications
and I/O workload in order to alleviate the effect of concurrent access
to I/O resources. The first algorithm (\nocoop) represents the status-quo  in
which applications are scheduled in a non-cooperative manner, which may
incur interference on I/O resource access and wait time. The second
algorithm (\fifoblock) inserts some coordination between I/O activities purely at
the filesystem level. Application that want to checkpoint are considered in
a FIFO ordering. When an application finishes a checkpoint, the head of
the line application is granted the checkpointing token and proceed,
other applications in the queue remain blocked in the checkpointing
routine. The third algorithm (\fifononblock) is similar, except it assumes
that burst buffers are available to absorb the temporary influx of
checkpoint data. In this case, the application blocks for the time it
takes to stage the checkpoint on the burst buffer, however, the application
receives full protection from fault only when the checkpoint is fully
migrated to the PFS. Last, we propose an heuristic (\leastwaste) whose goal is to
select the application that inflicts the least overhead on the system.
Each application checkpoints in a non-blocking manner, and instead of
following a FIFO order to select the next checkpointing application,
we compute the prospective waste incurred by selecting one of the
checkpointing applications, and select the best one at that moment. Note
that given the time dependent nature of that descision, the selection may
not be the global optimum, but only an approximation given currently
available information about the system status.

\subsection{Non-cooperative I/O Scheduling}

In the non-cooperative I/O scheduling, applications are selected to
fill-up the system based on processor count availability. The I/O
workload (including checkpointing activities) are not organized by any
comprehensive system. Instead, it is assumed that concurrent access
to I/O resources will cause a decrease in the application observed
bandwidth for I/O operations. One can imagine multiple cost functions
for the effect of that sharing; When the filesystem is scalable, the
overall throughput of the platform is maintained when multiple applications
concurently access, and each application observes a linear decrease in
the per-application bandwidth. As the application is blocking on the
completion of its I/O operations before it can continue, that decrease
in observed bandwidth leads to a proportionate increase in I/O time,
which in turn can generate a great amount of compute waste time
(where processors are idle waiting on I/O to complete).

\subsection{Blocking FIFO I/O Scheduling}

A simple optimization to the aforementionned scheme is to favor one of
the applications' I/O request over all others. While the overall throughput
may remain unchanged (given an efficient PFS implementation), the favored
application will complete its I/O workload faster (at nominal speed).
Applications will be favored in the order of their I/O requests, \ie
as soon as an application starts blocking on an I/O operation it will
take its place in the queue.

The advantage can be trivially seen in a simple workload with two applications
starting an I/O workload of volume $V$. If the two I/O requests
start simultaneously, in the previous strategy, and assuming a linear
interference model, both applications would use $V*2/\bandtotal$ time
to complete their I/O. In the \fifoblock strategy, the first application
(as determined by the queue serialization mechanism)
will take $V/\bandtotal$, while the second application will now wait
$V/\bandtotal$ before the I/O starts, but then enjoys the full use of
the I/O system and therefore complete in $V*2/\bandtotal$. In
average, the duration of the I/O workload has been reduced accross
applications (altough fairness has been decreased).

\subsection{Non-Blocking FIFO I/O Scheduling}

One of the major costs incurred stems from the fact that the I/O are
blocking. When considering normal application I/O, it is often
possible for the application programmer to refactor his code in order
to enable non-blocking I/O operation whose cost can then be
overlapped by other computing activities (although possibly less so
for initial and final input and output). In stark contrast,
checkpointing I/O workload is very time sensitive by nature.
Most commonly used types of checkpoints coordinate the
issuance of checkpoints from all processes of the application; when
that consistent global state has been established, the I/O operations
are initiated and no further application progress is possible until
it has completed. There are however techniques that exchange memory,
or the availability of a scratch space on the compute nodes (like a
local SSD drive used as a scratch buffer) that permit making the
checkpoint non-blocking. In the \fifononblock algorithm, the first
requesting application is still given full priority, however, unlike
in the previous algorithm, the cost of queueing the application is
greatly reduced and independent of the interference pattern, as we
consider that the application or the checkpointing system have been
modified to perform non-blocking, copy-on-write, or copy-to-scratchpad
mechanism.

\subsection{Least-waste algorithm}


\subsubsection{Strategy}

\begin{itemize}
  \item We always use the blocking strategy but not the FCFS policy.
  \item Instead, whenever an I/O operation completes at time $t$, we have a pool of application candidates:
  \begin{itemize}
   \item Category \IOcat $\Catiocat$: Applications $A_{i}$, $1\leq i \leq r$, which need to do input I/O, output I/O or recovery
  \item Category \Ckptcat $\Catckptcat$: Applications $A_{i}$, $r+1\leq i \leq r+s$,
  whose last checkpoint took place no later than time $t - \period{Daly}(A_{i})$, where $\period{Daly}(A_{i})$ is the Young/Daly period for $A_{i}$.
  \end{itemize}
  \item To decide which application is given priority among all $r+s$ candidates applications in $\Catiocat \cup \Catckptcat$, we select the one that minimizes the expected total waste induced by this choice, as explained below.
  \end{itemize}

 \subsubsection{Selection among candidate applications}

At the current time-step, there are $r+s$ candidates in $\Catiocat \cup \Catckptcat$:
\begin{itemize}
  \item Application $A_{i} \in \Catiocat$, $1\leq i \leq r$,
  has an I/O request of volume $v_{i}$ and enrolls $q_{i}$ processors. At the current time-step, $A_{i}$ initiated its I/O request $d_{i}$ seconds ago, and has been idle since $d_{i}$ seconds.
 \item Application $A_{i} \in  \Catckptcat$ has a checkpoint of duration $C_{i}$ seconds,
  and enrolls $q_{i}$ processors. At the current time-step, $A_{i}$ took its last checkpoint
  $d_{i}$ seconds ago, and keeps executing until it can checkpoint. For the record, we must have $d_{i} \geq \period{Daly}(A_{i})$
  since $A_{i}$ is a candidate.
  \end{itemize}

If we select application $A_{i}$ to perform I/O,  the expected waste $\wap{i}$ incurred
to the other $r+s-1$ candidate applications in  $\Catiocat \cup \Catckptcat$ is computed as follows.
Assume first that $A_{i} \in \Catiocat$. Then  $A_{i}$ will use the I/O resource for $v_{i}$ seconds.
\begin{itemize}
  \item Every other application $A_{j} \in \Catiocat$ will stay idle for $v_{i}$ additional seconds,
  hence its waste $\wapp{i}{j}$ is
  $$\wapp{i}{j} = q_{j} (d_{j} + v_{i})$$
  since there are $q_{j}$ processors enrolled in $A_{j}$ and idle for $d_{j} + v_{i}$ seconds. Note that for $A_{j} \in \Catiocat$, the waste $\wapp{i}{j}$ is deterministic.
  \item Every application $A_{j} \in \Catckptcat$ will continue executing for $v_{i}$ additional seconds, hence will be exposed to the risk of a failure that will strike within $v_{i}/2$ seconds on average. The probability of such a failure is $v_{i}/\mu_{j}$, where $\mu_{j}$ is the
  MTBF of application $A_{j}$. Since $A_{j}$ enrolls $q_{j}$ processors, we have $\mu_{j} = \muind/q_{j}$, where $\muind$ is the individual MTBF per processor. With this probability,
  the $q_{j}$ processors will have to recover and re-execute $d_{j} + v_{i}/2$ seconds of work,
  hence the waste $\wapp{i}{j}$ is
     $$\wapp{i}{j} = \frac{v_{i}}{\mu_{j} } q_{j} (R_{j} + d_{j} + \frac{v_{i}}{2}) =
     \frac{v_{i}}{\muind} q^{2}_{j} (R_{j} + d_{j} + \frac{v_{i}}{2})$$
     where $R_{j}$ is the recovery time for $A_{j}$.
Note that for $A_{j} \in \Catckptcat$, the waste $\wapp{i}{j}$ is probabilistic.
 \end{itemize}
 Altogether, the expected waste $\wap{i}$ incurred
to the other $r+s-1$ candidate applications is
$$\wap{i} = \sum_{A_{j} \in \Catiocat, j\neq i} \wapp{i}{j} + \sum_{A_{j} \in \Catckptcat} \wapp{i}{j}$$
We obtain
\begin{equation}
\label{eq.selection}
 \wap{i} = v_{i} \times \left( \sum_{1 \leq j \leq r, j\neq i} q_{j} (d_{j} + v_{i})
 + \sum_{r+1 \leq j \leq r+s}   \frac{q^{2}_{j}}{\muind} (R_{j} + d_{j} + \frac{v_{i}}{2}) \right)
\end{equation}

 Assume now that the selected application $A_{i} \in \Catckptcat$. Then  $A_{i}$ will use the I/O resource for $C_{i}$ seconds instead of $v_{i}$ seconds for $A_{i} \in \Catiocat$. We directly obtain the counterpart of Equation~\eqref{eq.selection} for its waste $\wap{i}$:
 \begin{equation}
\label{eq.selection2}
 \wap{i} = C_{i} \times \left( \sum_{1 \leq j \leq r} q_{j} (d_{j} + C_{i})
 + \sum_{r+1 \leq j \leq r+s, j\neq i}   \frac{q^{2}_{j}}{\muind} (R_{j} + d_{j} + \frac{C_{i}}{2}) \right)
\end{equation}

 Finally, we select the application $A_{i} \in \Catiocat \cup \Catckptcat$ whose waste
 $\wap{i}$ is minimal.


%\subsubsection{Selection in category \IOcat}
%\label{sec.iocat}
%
%  Let $(A_{i})_{1 \leq i \leq m}$ be the application candidates of category \IOcat.
%  Application $A_{i}$ has an I/O request of volume $v_{i}$ and enrolls $q_{i}$ processors.
%  Choosing $A_{i}$ makes every other candidate application $A_{j}$, $j \neq i$, keep $q_{j}$ processors idle during a time
%  proportional to $v_{i}$, so we choose $i$ that minimizes
%  $$(\sum_{j \neq i} q_{j}) \times v_{i}$$
%
%\subsubsection{Selection in category \Ckptcat}
%\label{sec.ckptcat}
%
%Let $(A_{i})_{1 \leq i \leq m}$ be the application candidates of category \Ckptcat.
%  Application $A_{i}$ has a checkpoint of duration $C_{i}$ seconds,
%  and enrolls $q_{i}$ processors. At the current time-step, $A_{i}$ took its last checkpoint
%  $d_{i}$ seconds ago (and for the record, we must have $d_{i} \geq \period{Daly}(A_{i})$
%  since $A_{i}$ is a candidate).
%   Choosing $A_{i}$ puts every other candidate application $A_{j}$, $j \neq i$,
%   at the risk of a failure that will strike within $C_{i}/2$ seconds on average.
%   Let $\bar{Q}_{i} = \sum_{j \neq i}q_{j}$ be the total number of
%   processors belonging to applications that want to checkpoint.
%   With probability $C_{i}/(\muind/\bar{Q}_{i})$ there will be a fault on one of these
%   processors. Here $\muind$ is the individual MTBF, hence we divide it by $\bar{Q}_{i}$
%   to get the MTBF over all processors at risk.
%
%   With probability $q_{j}/\bar{Q}_{i}$ the fault will strike application $A_{j}$ and incur a waste of duration $d_{j} + C_{i}/2$ for each of its $q_{j}$ processors. Altogether, the
%   expected amount of wasted time is
%   $$\frac{C_{i}}{(\muind/\bar{Q}_{i}) } \times \sum_{j \neq i}\frac{q_{j}}{\bar{Q}_{i}}(d_{j}+ \frac{C_{i}}{2})q_{j} = \frac{C_{i}}{\muind} \sum_{j \neq i} q_{j}^{2}(d_{j}+ \frac{C_{i}}{2})$$
%    and we choose $i$ that minimizes the above quantity.
