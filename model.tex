% !TEX root =  ipdps18.tex

\section{Model}
\label{sec:model}
% Primary: Yves

\paragraph*{Computational Platform Model}

In this work, we consider a shared platform comprised of computational
nodes, storage resources in the form of a parallel file system (PFS), and a network
that interconnects the nodes and storage resources. Applications are
scheduled on the platform by a job scheduler such that computational nodes are
space-shared (dedicated) amongst concurrent application instances. However, the I/O
subsystem is time-shared (contended) amongst application instances  (\ie multiple
applications performing I/O simultaneously result in a per-application reduction
in commit speed). Without loss of generality, we consider a straightforward linear
interference model in which the global throughput remains constant and is evenly
shared among contending applications, proportional to their size\footnote{A more
adversarial interference model can be substituted, if needed.}.

\paragraph*{Application Workload Model}

Applications can vary in size (computational node count), duration, memory
footprint and I/O requirements.  \emph{Application I/O} entails loading an input file
at startup, performing regular I/O operations during their main execution phase and
storing an output file at completion. Because applications are long-running,
(typically, several hours or days) and the platform is failure-prone, applications
are protected using coordinated CR that incurs periodic \emph{CR I/O}.

To model these behavioral variations with minimal parameters, we make the following
simplifying assumptions:
\begin{compactitem}
\item There is a large number of applications, but only a small number of application
  classes, \ie, sets of applications with similar sizes, durations, footprints and
  I/O needs;
\item Excluding initialization and finalization I/O, an application's regular
  (non-CR) I/O operations are evenly distributed over its makespan;
\item Job makespans are known a priori. This allows us to ignore all other
  sources of job disturbance except C/R overheads.
\end{compactitem}

We use specific numbers and characteristics of application classes based on
documented production workloads, such as those provided in the APEX workflows report
on the Cielo platform~\cite{apex2016}.  To avoid the side effects induced by
hundreds of completely identical jobs, we use a normal distributions for job
durations with a mean equal to original APEX value and small (20\%) standard
deviation.  In the rest of the paper, we use the term \emph{job} to denote
a specific application instance, and \emph{application class} to denote a set
of applications with similar characteristics.

\paragraph*{Checkpoint Period and I/O Interference}

Both application computation and CR generate I/O requests.  In both cases,
activity is scheduled using an I/O scheduling algorithm (see
\Cref{sec:algorithms}). As described above, steady-state application I/O is
regular. However, CR I/O periodicity, $P$, depends upon the CR policy being
used.  In our model, applications either checkpoint using an
application-defined periodicity or using Young and Daly's~\cite{young74,daly04}
optimal checkpoint period detailed in \Cref{sec:intro}. As stated previously,
the parameters in this formula are dependent upon application features
(checkpoint dataset size) and platform features (system reliability and I/O
bandwidth).

Traditionally, when a job $J_{i}$ of class $\app{i}$ completes a checkpoint, its next
checkpoint is scheduled to happen in at least $\period{i}-\ckpt{i}$ (and the first
checkpoint is set at date $\period{i}$). With potential CR I/O interference,
the checkpoint commit may last longer than $\ckpt{i}$, and setting
the appropriate checkpointing period can be challenging.
Additionally, I/O scheduling algorithms that try to mitigate I/O interference can
impose further CR I/O delays.  In other words, the traditional strategy of scheduling
subsequent checkpoints at $\period{i}-\ckpt{i}$ yields the desired checkpointing
period $\period{i}$ only in interference-free scenarios. CR I/O delays (induced by
interferences or scheduling delays) dilate the checkpoint duration to $C_{dilated}$,
and the effective period differs from the desired period by the difference
$C_{dilated}-\ckpt{i}$.  \Cref{sec:algorithms} discusses how each I/O
scheduling algorithm handles this discrepancy.

\paragraph*{Job Scheduling Model}

To evaluate the scheduling policies, we consider a finite segment, typically
lasting a few days, of a representative schedule where the computing resource
usage by each application instance (job) in each class remains nearly constant.
Of course, with varying job execution times, we cannot enforce a fixed
proportion of each application class at every instant. However, we ensure the
proper proportion is enforced on average throughout the schedule execution.
Similarly, we enforce that at every instant during the finite segment, at least
98\% of the nodes are enrolled for the execution. This allows us to compare
actual (simulated) performance with the theoretical performance of a
co-scheduling policy that optimizes the steady-state I/O behavior of the job
portfolio, assuming that all processors are used. We shuffle and simultaneously
present all jobs to the scheduler, which uses a simple, greedy first-fit
algorithm.  We resubmit failed jobs with a new wall-time equal to the fraction
that remained when the last checkpoint commit started.  In this case, input I/O
becomes recovery I/O; output I/O is unmodified.

\paragraph*{The Formal Model}

We consider a set $\appset$ of $\nbapps$ applications classes
$\app{1}, \ldots \app{\nbapps}$ that execute concurrently on a platform with
$\nbnodesplat$ nodes. Application class $\app{i}$ specifies:
\begin{compactitem}
\item $\nbapp{i}$: the number of jobs in $\app{i}$,
\item $\nbnodes{i}$: the number of nodes used by each job in $\app{i}$,
\item $\period{i}$: the checkpoint period of each job in $\app{i}$, and
\item $\ckpt{i}$ and $\reco{i}$: the checkpoint and recovery durations for each job in $\app{i}$ when there is no interference with other I/O operations.
\end{compactitem}

To simplify notation, where unambiguous we extend the notations to jobs: for a
job $J_j$ belonging to application class $\app{i}$, $\nbnodes{j} =
\nbnodes{i}$, $\period{j} = \period{i}$, $\ckpt{j} = \ckpt{i}$, and $\reco{j} =
\reco{i}$ denote the number of nodes used by job $j$, the checkpoint period of
job $j$ and the checkpoint and recovery durations of job $j$ respectfully.  At
each instance, we schedule as many jobs as possible.  Jobs that are subject to
failures are restarted at the head of the scheduling queue, as to restart
immediately on the same compute nodes previously used (In most cases, only one
node has failed and is replaced by a hot spare).
